<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>NeRO: Neural Geometry and BRDF Reconstruction of Reflective Objects from Multiview Images</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <!-- <link href='http://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,800italic,400,700,800' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="css/project.css" media="screen" />
    <link rel="stylesheet" type="text/css" media="screen" href="css/iconize.css" />
    <script src="js/google-code-prettify/prettify.js"></script> -->
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2>NeRO: <u>Ne</u>ural Geometry and BRDF Reconstruction of <br> <u>R</u>eflective <u>O</u>bjects from Multiview Images
            </h2>
            <h4 style="color:#5a6268;">SIGGRAPH 2023</h4>
            <hr>
            <h6>
                <a href="https://liuyuan-pal.github.io/" target="_blank">Yuan Liu</a><sup>1</sup>,
                <a href="https://totoro97.github.io" target="_blank">Peng Wang</a><sup>1</sup>,
                <a href="https://clinplayer.github.io/" target="_blank">Cheng Lin</a><sup>2</sup>,
                <a href="https://www.xxlong.site/" target="_blank">Xiaoxiao Long</a><sup>1</sup>,
                <a href="https://jiepengwang.github.io/" target="_blank">Jiepeng Wang</a><sup>1</sup>,
                <a href="https://lingjie0206.github.io/" target="_blank">Lingjie Liu</a><sup>3,4</sup>,
                <a href="https://homepages.inf.ed.ac.uk/tkomura/" target="_blank">Taku Komura</a><sup>1</sup>,
                <a href="https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html" target="_blank">Wenping Wang</a><sup>5</sup></h6>
            <p>
                <sup>1</sup>The University of Hong Kong &nbsp;&nbsp;
                <sup>2</sup>Tencent Game&nbsp;&nbsp;&nbsp;&nbsp;
                <sup>3</sup>University of Pennsylvania &nbsp;&nbsp;&nbsp;&nbsp;
                <sup>4</sup>Max Planck Institute for Informatics &nbsp;&nbsp;&nbsp;&nbsp;
                <sup>5</sup>Texas A&M University
            </p>

            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/liuyuan-pal/NeRO" role="button"  target="_blank">
                    <i class="fa fa-github-alt"></i> Code </a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="" role="button"  target="_blank">
                    <i class="fa fa-database"></i> Model & Dataset </a> </p>
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
            <h6 style="color:#8899a5"> NeRO is able to reconstruct both shape and BRDF of reflective objects using only multiview images. </h6>
<!--            <div align="center"> For an unseen objects, we can simply take. </div>-->

            <div class="row" style="margin-bottom:5px">
              <div class="col" style="text-align:center">
                <img class="thumbnail" src="image/teaser_v3.jpg" style="width:100%; margin-bottom:20px">
              </div>

            </div>
			<br>

          <p class="text-left">
            We present a neural rendering-based method called NeRO for reconstructing the geometry and the BRDF of reflective objects from multiview images captured in an unknown environment. Multiview reconstruction of reflective objects is extremely challenging because specular reflections are view-dependent and thus violate the multiview consistency, which is the cornerstone for most multiview reconstruction methods. Recent neural rendering techniques can model the interaction between environment lights and the object surfaces to fit the view-dependent reflections, thus making it possible to reconstruct reflective objects from multiview images. However, accurately modeling environment lights in the neural rendering is intractable, especially when the geometry is unknown. Most existing neural rendering methods, which can model environment lights, only consider direct lights and rely on object masks to reconstruct objects with weak specular reflections. Therefore, these methods fail to reconstruct reflective objects, especially when the object mask is not available and the object is illuminated by indirect lights. We propose a two-step approach to tackle this problem. First, by applying the split-sum approximation and the integrated directional encoding to approximate the shading effects of both direct and indirect lights, we are able to accurately reconstruct the geometry of reflective objects without any object masks. Then, with the object geometry fixed, we use more accurate sampling to recover the environment lights and the BRDF of the object. Extensive experiments demonstrate that our method is capable of accurately reconstructing the geometry and the BRDF of reflective objects from only posed RGB images without knowing the environment lights and the object masks.
          </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h2>Comparison on Shape Reconstruction</h2>
            <hr style="margin-top:0px">
            <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="video/geom_compare_compressed.mp4" type="video/mp4">
            </video>
          <p class="text-center">
            In comparison with: COLMAP [1] NeuS [2] Ref-NeRF [3] NvDiffRecMC [4]
          </p>
          <p class="text-left">
            [1] Pixelwise view selection for unstructured multi-view stereo. ECCV 2016. <br>
            [2] NeuS: Learning neural implicit surfaces by volume rendering for multi-view reconstruction. NeurIPS 2021. <br>
            [3] Ref-NeRF: Structured view-dependent appearance for neural radiance fields. CVPR 2022. <br>
            [4] Shape, Light, and Material Decomposition from Images using Monte Carlo Rendering and Denoising. NeurIPS 2022. <br>
          </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h2>Comparison on Relighting</h2>
            <hr style="margin-top:0px">
            <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="video/relight_compare_compressed.mp4" type="video/mp4">
            </video>

          <p class="text-center">
            In comparison with: MII [1] NeILF [2] NvDiffRecMC [3]
          </p>
          <p class="text-left">
            [1] Modeling Indirect Illumination for Inverse Rendering. CVPR 2022. <br>
            [2] NeiLF: Neural incident light field for physically-based material estimation. ECCV 2022. <br>
            [3] Shape, Light, and Material Decomposition from Images using Monte Carlo Rendering and Denoising. NeurIPS 2022. <br>
          </p>
        </div>
      </div>
    </div>
  </section>
  <br>
<!--  <section>-->
<!--    <div class="container">-->
<!--      <div class="row">-->
<!--        <div class="col-12 text-center">-->
<!--            <h2>Results with 10k per-scene training steps (~40min)</h2>-->
<!--            <hr style="margin-top:0px">-->
<!--            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">-->
<!--                <source src="video/nerf_syn_ft_comparison.mp4" type="video/mp4">-->
<!--            </video>-->
<!--            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">-->
<!--                <source src="video/nerf_syn_ft.mp4" type="video/mp4">-->
<!--            </video>-->
<!--            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">-->
<!--                <source src="video/dtu_ft.mp4" type="video/mp4">-->
<!--            </video>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </section>-->
<!--  <br>-->

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h2>More Shape Reconstruction</h2>
            <hr style="margin-top:0px">
            <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="video/geom_results_compressed.mp4" type="video/mp4">
            </video>

          <p class="text-left">

          </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h2>More Relighting</h2>
            <hr style="margin-top:0px">
            <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="video/relight_results_compressed.mp4" type="video/mp4">
            </video>

          <p class="text-left">

          </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@inproceedings{liu2023nero,
  title={NeRO: Neural Geometry and BRDF Reconstruction of Reflective Objects from Multiview Images},
  author={Liu, Yuan and Wang, Peng and Lin, Cheng and Long, Xiaoxiao and Wang, Jiepeng and Liu, Lingjie and Komura, Taku and Wang, Wenping},
  year={2023}
}</code></pre>
          <hr>
      </div>
    </div>
  </div>

  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>

</body>
</html>
